{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de57c5c0",
   "metadata": {},
   "source": [
    "# Goal\n",
    "Build a simple VAE model based on the MNIST dataset.\n",
    "\n",
    "1. Install dependencies\n",
    "2. Select device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d9616ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/chelseaguo/Documents/MDST Text to Image Generator/F25-text-to-image-generator/venv/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/chelseaguo/Documents/MDST Text to Image Generator/F25-text-to-image-generator/venv/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/chelseaguo/Documents/MDST Text to Image Generator/F25-text-to-image-generator/venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/chelseaguo/Documents/MDST Text to Image Generator/F25-text-to-image-generator/venv/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/chelseaguo/Documents/MDST Text to Image Generator/F25-text-to-image-generator/venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 519, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/chelseaguo/Documents/MDST Text to Image Generator/F25-text-to-image-generator/venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 508, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/chelseaguo/Documents/MDST Text to Image Generator/F25-text-to-image-generator/venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/chelseaguo/Documents/MDST Text to Image Generator/F25-text-to-image-generator/venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 368, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/chelseaguo/Documents/MDST Text to Image Generator/F25-text-to-image-generator/venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/chelseaguo/Documents/MDST Text to Image Generator/F25-text-to-image-generator/venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 455, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/chelseaguo/Documents/MDST Text to Image Generator/F25-text-to-image-generator/venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 577, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/chelseaguo/Documents/MDST Text to Image Generator/F25-text-to-image-generator/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/chelseaguo/Documents/MDST Text to Image Generator/F25-text-to-image-generator/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/chelseaguo/Documents/MDST Text to Image Generator/F25-text-to-image-generator/venv/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/chelseaguo/Documents/MDST Text to Image Generator/F25-text-to-image-generator/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/chelseaguo/Documents/MDST Text to Image Generator/F25-text-to-image-generator/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/chelseaguo/Documents/MDST Text to Image Generator/F25-text-to-image-generator/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/t8/8tgpq95147d7vj4l3sg7v1rw0000gn/T/ipykernel_26529/3449040899.py\", line 3, in <module>\n",
      "    import torch.utils.data\n",
      "  File \"/Users/chelseaguo/Documents/MDST Text to Image Generator/F25-text-to-image-generator/venv/lib/python3.11/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/chelseaguo/Documents/MDST Text to Image Generator/F25-text-to-image-generator/venv/lib/python3.11/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/chelseaguo/Documents/MDST Text to Image Generator/F25-text-to-image-generator/venv/lib/python3.11/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/chelseaguo/Documents/MDST Text to Image Generator/F25-text-to-image-generator/venv/lib/python3.11/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/chelseaguo/Documents/MDST Text to Image Generator/F25-text-to-image-generator/venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/chelseaguo/Documents/MDST Text to Image Generator/F25-text-to-image-generator/venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f957906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "# Device selection\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using GPU\")\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    print(\"Using MPS\")\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1}\n",
    "if torch.cuda.is_available():\n",
    "    kwargs['pin_memory'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c934c013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "batch_size = 64\n",
    "latent_size = 32\n",
    "init_channels = 8\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdd1e1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)>\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error downloading train-images-idx3-ubyte.gz",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Download the MNIST dataset\u001b[39;00m\n\u001b[32m      3\u001b[39m train_loader = torch.utils.data.DataLoader(\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43mdatasets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMNIST\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransforms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mToTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m      7\u001b[39m     batch_size=batch_size, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m, **kwargs)\n\u001b[32m      8\u001b[39m test_loader = torch.utils.data.DataLoader(\n\u001b[32m      9\u001b[39m     datasets.MNIST(\n\u001b[32m     10\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m, train=\u001b[38;5;28;01mFalse\u001b[39;00m, transform=transforms.ToTensor()),\n\u001b[32m     11\u001b[39m     batch_size=batch_size, shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MDST Text to Image Generator/F25-text-to-image-generator/venv/lib/python3.11/site-packages/torchvision/datasets/mnist.py:99\u001b[39m, in \u001b[36mMNIST.__init__\u001b[39m\u001b[34m(self, root, train, transform, target_transform, download)\u001b[39m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._check_exists():\n\u001b[32m    102\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mDataset not found. You can use download=True to download it\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MDST Text to Image Generator/F25-text-to-image-generator/venv/lib/python3.11/site-packages/torchvision/datasets/mnist.py:195\u001b[39m, in \u001b[36mMNIST.download\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    193\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError downloading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error downloading train-images-idx3-ubyte.gz"
     ]
    }
   ],
   "source": [
    "# Download the MNIST dataset\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        'data', train=True, download=True,\n",
    "        transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        'data', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eef821",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_channels, init_channels, latent_size):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(image_channels, init_channels, kernel_size = 4, stride = 2, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(init_channels, init_channels * 2, kernel_size = 4, stride = 2, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(init_channels * 2, init_channels * 4, kernel_size = 4, stride = 2, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(init_channels * 4, init_channels * 8, kernel_size = 4),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # FC layers to get mu and logvar\n",
    "        self.fc1 = nn.Linear(64, 128)\n",
    "        self.fc_mu = nn.Linear(128, latent_size)\n",
    "        self.fc_logvar = nn.Linear(128, latent_size)\n",
    "        self.fc2 = nn.Linear(latent_size, 64)\n",
    "        \n",
    "        # decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(init_channels * 8, init_channels * 4, kernel_size = 4),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(init_channels * 4, init_channels * 2, kernel_size = 4, stride = 2, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(init_channels * 2, init_channels, kernel_size = 4, stride = 2, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(init_channels, image_channels, kernel_size = 4, stride = 2, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(1, 1, kernel_size = 5, padding = 2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        h = h.view(h.size(0), -1)        \n",
    "        h_fc = F.relu(self.fc1(h))\n",
    "        mu = self.fc_mu(h_fc)\n",
    "        logvar = self.fc_logvar(h_fc)\n",
    "        return mu, logvar\n",
    "    \n",
    "    # mu: mean vector\n",
    "    # logvar: log variance vector\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        # TODO: Define the reparameterization function\n",
    "        \n",
    "        return None  # Delete this line before you begin\n",
    "    \n",
    "    def decode(self, z):\n",
    "        h = F.relu(self.fc2(z))\n",
    "        h = h.view(-1, 64, 1, 1)\n",
    "        \n",
    "        return torch.sigmoid(self.decoder(h))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon_x = self.decode(z)\n",
    "        return recon_x, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc6b672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recon_x: reconstructed images\n",
    "# x: original input images\n",
    "# mu: mean vector\n",
    "# logvar: log variance vector\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    # TODO: Define the reconstruction loss(binary cross entropy) term and KL divergence term\n",
    "    \n",
    "    return None     # Delete this line before you begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5c2113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test functions\n",
    "def train(model, optimizer, epoch, losses):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.detach().cpu().numpy()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 20 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item() / len(data)))\n",
    "    \n",
    "    losses.append(train_loss / len(train_loader.dataset))\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))\n",
    "\n",
    "def test(model, epoch, losses):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            test_loss += loss_function(recon_batch, data, mu, logvar).detach().cpu().numpy()\n",
    "            if i == 0:\n",
    "                n = min(data.size(0), 5)\n",
    "                comparison = torch.cat([data[:n],\n",
    "                                      recon_batch.view(-1, 1, 28, 28)[:n]])\n",
    "                save_image(comparison.cpu(),\n",
    "                         'reconstruction_' + str(f\"{epoch:02}\") + '.png', nrow=n)\n",
    "\n",
    "    losses.append(test_loss / len(test_loader.dataset))\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ec24fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(image_channels=1, init_channels=init_channels, latent_size=latent_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, optimizer, epoch, train_losses)\n",
    "    test(model, epoch, test_losses)\n",
    "    with torch.no_grad():\n",
    "        sample = torch.randn(10, latent_size).to(device)\n",
    "        sample = model.decode(sample).to(device)\n",
    "        save_image(sample.view(10, 1, 28, 28), str(f\"sample_{epoch:02}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4025e06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the training and test losses\n",
    "import matplotlib.pyplot as plt\n",
    "print(train_losses)\n",
    "print(test_losses)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(test_losses, label='Test Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Test Losses')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856ce2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "import torchvision.models as models\n",
    "\n",
    "torch.save(model.state_dict(), 'vae_model_mnist.pth' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c8c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "\n",
    "model = VAE(image_channels=1, init_channels=init_channels, latent_size=latent_size).to(device)\n",
    "model.load_state_dict(torch.load('vae_model_mnist.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dcbe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "\n",
    "def generate_digit(model, num_samples=1):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        sample = torch.randn(num_samples, latent_size).to(device)\n",
    "        sample = model.decode(sample).to(device)\n",
    "        \n",
    "        save_image(sample.view(num_samples, 1, 28, 28), f\"generated_sample.png\")\n",
    "\n",
    "generate_digit(model, num_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc457cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
